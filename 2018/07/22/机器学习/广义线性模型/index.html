<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="广义线性模型1、普通最小二乘法 最小二乘的系数估计依赖于模型特征项的独立性。当特征项相关并且设计矩阵 的列近似的线性相关时，设计矩阵便接近于一个奇异矩阵，因此最小二乘估计对观测点中的随机误差变得高度敏感，产生大的方差。例如，当没有试验设计的收集数据时，可能会出现这种多重共线性(multicollinearity )的情况。   2、岭回归、岭回归加交叉验证 岭回归通过对系数的大小施加惩罚来解决普通">
<meta property="og:type" content="article">
<meta property="og:title" content="广义线性模型">
<meta property="og:url" content="http://yoursite.com/2018/07/22/机器学习/广义线性模型/index.html">
<meta property="og:site_name" content="热雪的博客">
<meta property="og:description" content="广义线性模型1、普通最小二乘法 最小二乘的系数估计依赖于模型特征项的独立性。当特征项相关并且设计矩阵 的列近似的线性相关时，设计矩阵便接近于一个奇异矩阵，因此最小二乘估计对观测点中的随机误差变得高度敏感，产生大的方差。例如，当没有试验设计的收集数据时，可能会出现这种多重共线性(multicollinearity )的情况。   2、岭回归、岭回归加交叉验证 岭回归通过对系数的大小施加惩罚来解决普通">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/square.PNG">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/7a7bb470119808e2db2879fc2b2526f467b7a40b.png">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/ridge.PNG">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/lasso.PNG">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/multi_lasso.PNG">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/elastic.PNG">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/ela_vs_lasso.PNG">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/a4acdafd29eec35831ca225d906e7691941d9567.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/f77f5b2c6971d3c72c400d10b87707edc1d7156d.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/4dc06edd94309641af4846043fe7c7b650e40037.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/f478d5b226c02754ede31ce247d4d9870ff7c416.png">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/beyes.PNG">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/8cef10bb133d7cb70cdf6433fc0cbef817b7b5aa.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/03fb95641efd224604d31e10ad0d43f2a1981cfe.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/e0dbb05b8bf9656ef6b32514010a9bfe514c9945.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/149c8337ae0f9ffc3e3c6021f779738b650ae69f.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/8cef10bb133d7cb70cdf6433fc0cbef817b7b5aa.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/159e1bfcbbeedf7e28983ee80db2b2d37c3b3ebc.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/159e1bfcbbeedf7e28983ee80db2b2d37c3b3ebc.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/a2c5c1af213db8e97bdaaf60c8fceab2faef8271.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/6bf459c11ce1eb9a1bfa05d02185f322e796f5f4.png">
<meta property="og:image" content="http://yoursite.com/image/机器学习/广义线性模型/adr_vs_sq.PNG">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/760c999ccbc78b72d2a91186ba55ce37f0d2cf37.png">
<meta property="og:image" content="http://scikit-learn.org/stable/_images/math/6a0bcf21baaeb0c2b879ab74fe333c0aab0d6ae6.png">
<meta property="og:updated_time" content="2018-07-24T13:53:10.390Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="广义线性模型">
<meta name="twitter:description" content="广义线性模型1、普通最小二乘法 最小二乘的系数估计依赖于模型特征项的独立性。当特征项相关并且设计矩阵 的列近似的线性相关时，设计矩阵便接近于一个奇异矩阵，因此最小二乘估计对观测点中的随机误差变得高度敏感，产生大的方差。例如，当没有试验设计的收集数据时，可能会出现这种多重共线性(multicollinearity )的情况。   2、岭回归、岭回归加交叉验证 岭回归通过对系数的大小施加惩罚来解决普通">
<meta name="twitter:image" content="http://yoursite.com/image/机器学习/广义线性模型/square.PNG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"right","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/07/22/机器学习/广义线性模型/"/>





  <title>广义线性模型 | 热雪的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>
    

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">热雪的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/./" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/22/机器学习/广义线性模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://i.loli.net/2018/07/21/5b5347273dca4.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="热雪的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">广义线性模型</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-22T00:24:54+08:00">
                2018-07-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h3><h3 id="1、普通最小二乘法"><a href="#1、普通最小二乘法" class="headerlink" title="1、普通最小二乘法"></a>1、普通最小二乘法</h3><p><img src="/image/机器学习/广义线性模型/square.PNG" alt=""></p>
<p>最小二乘的系数估计依赖于模型特征项的独立性。当特征项相关并且设计矩阵<img src="http://scikit-learn.org/stable/_images/math/7a7bb470119808e2db2879fc2b2526f467b7a40b.png" alt="X"> 的列近似的线性相关时，设计矩阵便接近于一个奇异矩阵，因此最小二乘估计对观测点中的随机误差变得高度敏感，产生大的方差。例如，当没有试验设计的收集数据时，可能会出现这种多重共线性(<em>multicollinearity</em> )的情况。 </p>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h3 id="2、岭回归、岭回归加交叉验证"><a href="#2、岭回归、岭回归加交叉验证" class="headerlink" title="2、岭回归、岭回归加交叉验证"></a>2、岭回归、岭回归加交叉验证</h3><p><img src="/image/机器学习/广义线性模型/ridge.PNG" alt=""></p>
<p>岭回归通过对系数的大小施加惩罚来解决普通最小二乘的问题。</p>
<h3 id="3、Lasso"><a href="#3、Lasso" class="headerlink" title="3、Lasso"></a>3、Lasso</h3><p><img src="/image/机器学习/广义线性模型/lasso.PNG" alt=""></p>
<p>估计稀疏系数的线性模型 。它在一些情况下是有用的，因为它倾向于使用具有较少参数值的解决方案，有效地减少给定解决方案所依赖的变量的数量。 </p>
<p><strong>Lasso</strong> 类中的实现使用坐标下降作为算法来拟合系数。 </p>
<p>由于 <strong>Lasso</strong> 回归生成稀疏模型，因此可以用于实现特征选择 。</p>
<p>4、Multi-task Lasso ( 多任务套索 )</p>
<p><img src="/image/机器学习/广义线性模型/multi_lasso.PNG" alt=""></p>
<p><strong>MultiTaskLasso</strong> 是一个线性模型，它联合估计多个回归问题的稀疏系数：y 是一个二维数组，<strong>shape(n_samples，n_tasks)</strong>。约束是所选的特征对于所有的回归问题都是相同的，也称为 <strong>tasks</strong> ( 任务 )。</p>
<p> <strong>Lasso</strong> 估计产生分散的非零，而 <strong>MultiTaskLasso</strong> 的非零是全部。</p>
<p>拟合 <strong>time-series model</strong> ( 时间序列模型 )，强制任何活动的功能始终处于活动状态。</p>
<p>5、Elastic Net ( 弹性网 )、ElasticNetCV类</p>
<p><img src="/image/机器学习/广义线性模型/elastic.PNG" alt=""></p>
<p><strong>ElasticNet</strong> 是一种线性回归模型，以 <strong>L1</strong> 和 <strong>L2</strong> 训练为正规化。这种组合允许学习一个稀疏模型，其中很少的权重是非零的 。</p>
<p>当有多个相互关联的特征时，<strong>Elastic-net</strong> 是有用的。 <strong>Lasso</strong> 有可能随机选择其中之一，而 <strong>elastic-net</strong> 则很可能选择两者。 </p>
<p><strong>Lasso</strong> 和 <strong>Ridge</strong> 之间的一个实际的优势是允许 <strong>Elastic-Net</strong> 继承 <strong>Ridge</strong> 在一些旋转下的稳定性。 </p>
<p>比较：<img src="/image/机器学习/广义线性模型/ela_vs_lasso.PNG" alt=""></p>
<p>该程序设置l1_ratio=0.8，根据公式知道L1范数偏重，也就是此时在相同的a下，lasso的算出来的w（coe）会比elastic的大；当l1_ratio=0.5，两者的w接近相同。</p>
<h3 id="6、LARS-Lasso使用最小角度回归的拉索算法"><a href="#6、LARS-Lasso使用最小角度回归的拉索算法" class="headerlink" title="6、LARS Lasso使用最小角度回归的拉索算法"></a>6、LARS Lasso使用最小角度回归的拉索算法</h3><p>与基于 <strong>coordinate_descent</strong> 的实现不同，这产生了精确的解，其作为其系数范数的函数是分段线性的。 </p>
<h3 id="7、Orthogonal-Matching-Pursuit-OMP-正交匹配追踪（OMP）"><a href="#7、Orthogonal-Matching-Pursuit-OMP-正交匹配追踪（OMP）" class="headerlink" title="7、Orthogonal Matching Pursuit (OMP) ( 正交匹配追踪（OMP） )"></a>7、Orthogonal Matching Pursuit (OMP) ( 正交匹配追踪（OMP） )</h3><p>用于近似线性模型的拟合，并对非零系数（即 <strong>L 0</strong> 伪范数）施加约束。 作为  <strong>Least Angle Regression</strong> (  最小角度回归 ) 的前向特征选择方法，正交匹配追踪可以用固定数量的非零元素逼近最优解矢量： <img src="http://scikit-learn.org/stable/_images/math/a4acdafd29eec35831ca225d906e7691941d9567.png" alt="img">  </p>
<p><strong>OMP</strong> 基于一个贪心算法，每个步骤都包含与当前残差最相关的原子。它类似于更简单的匹配追求（ <strong>MP</strong> ）方法，但是在每次迭代中更好，使用在先前选择的词典元素的空间上的正交投影重新计算残差。 </p>
<h3 id="8、Bayesian-Regression-贝叶斯回归"><a href="#8、Bayesian-Regression-贝叶斯回归" class="headerlink" title="8、Bayesian Regression ( 贝叶斯回归 )"></a>8、Bayesian Regression ( 贝叶斯回归 )</h3><p>贝叶斯回归技术可以用于在估计过程中包括正则化参数：正则化参数不是硬的设置，而是调整到手头的数据。<br>这可以通过对模型的超参数引入 <strong>uninformative priors</strong> ( 不知情的先验 ) 来完成。<strong>Ridge Regression</strong>  中使用的<img src="http://scikit-learn.org/stable/_images/math/f77f5b2c6971d3c72c400d10b87707edc1d7156d.png" alt="img"> 正则化等价于在精度为？的参数 <img src="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png" alt="w"> 之前，在高斯下找到最大 <strong>a-postiori</strong> 解。而不是手动设置 <strong>lambda</strong> ，可以将其视为从数据估计的随机变量。<br>为了获得一个完全概率模型，输出y被假定为高斯分布在 <img src="http://scikit-learn.org/stable/_images/math/4dc06edd94309641af4846043fe7c7b650e40037.png" alt="X w"> 周围：<br><img src="http://scikit-learn.org/stable/_images/math/f478d5b226c02754ede31ce247d4d9870ff7c416.png" alt="img"><br><strong>Alpha</strong> 再次被视为从数据估计的随机变量。<br>贝叶斯回归的优点是：</p>
<ul>
<li>它适应了 <strong>data at hand</strong> ( 手头的数据 ) 。</li>
<li>它可以用于在估计过程中包括正则化参数。</li>
</ul>
<p>贝叶斯回归的缺点包括：</p>
<ul>
<li>模型的推论可能是耗时的。</li>
</ul>
<p><img src="/image/机器学习/广义线性模型/beyes.PNG" alt=""></p>
<h3 id="9、Automatic-Relevance-Determination-ARD-自动相关性测定-ARD"><a href="#9、Automatic-Relevance-Determination-ARD-自动相关性测定-ARD" class="headerlink" title="9、Automatic Relevance Determination - ARD ( 自动相关性测定 - ARD )"></a>9、Automatic Relevance Determination - ARD ( 自动相关性测定 - ARD )</h3><p> <strong>ARDRegression</strong> 与 <strong>Bayesian Ridge Regression</strong> ( 贝叶斯岭回归 ) 非常相似，但可以导致更稀疏的权重  <img src="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png" alt="w">  </p>
<p><strong>ARDREgression</strong> 通过放弃高斯为球面的假设，构成了与 <img src="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png" alt="w"> 之前不同的先验。 相反，假定 <img src="http://scikit-learn.org/stable/_images/math/ecd1ee2a1cd226b40c37e079aca62398d4b774f5.png" alt="w"> 上的分布是轴平行的椭圆高斯分布。 这意味着每个权重 <img src="http://scikit-learn.org/stable/_images/math/8cef10bb133d7cb70cdf6433fc0cbef817b7b5aa.png" alt="img"> 从高斯分布绘制，以零为中心，精度为 <img src="http://scikit-learn.org/stable/_images/math/03fb95641efd224604d31e10ad0d43f2a1981cfe.png" alt="img"> ： <img src="http://scikit-learn.org/stable/_images/math/e0dbb05b8bf9656ef6b32514010a9bfe514c9945.png" alt="img"> 与 <img src="http://scikit-learn.org/stable/_images/math/149c8337ae0f9ffc3e3c6021f779738b650ae69f.png" alt="img"> 。 与贝叶斯岭回归相反，每个 <img src="http://scikit-learn.org/stable/_images/math/8cef10bb133d7cb70cdf6433fc0cbef817b7b5aa.png" alt="img"> 的坐标都有自己的标准偏差<img src="http://scikit-learn.org/stable/_images/math/159e1bfcbbeedf7e28983ee80db2b2d37c3b3ebc.png" alt="img"> 。 先前的所有 <img src="http://scikit-learn.org/stable/_images/math/159e1bfcbbeedf7e28983ee80db2b2d37c3b3ebc.png" alt="img"> 被选择为由超参数 <img src="http://scikit-learn.org/stable/_images/math/a2c5c1af213db8e97bdaaf60c8fceab2faef8271.png" alt="img">和 <img src="http://scikit-learn.org/stable/_images/math/6bf459c11ce1eb9a1bfa05d02185f322e796f5f4.png" alt="img"> 给出的相同的伽马分布。 </p>
<p><img src="/image/机器学习/广义线性模型/adr_vs_sq.PNG" alt=""></p>
<h3 id="10、Logistic-regression-逻辑回归"><a href="#10、Logistic-regression-逻辑回归" class="headerlink" title="10、Logistic regression ( 逻辑回归 )"></a>10、Logistic regression ( 逻辑回归 )</h3><p><strong>Logistic regression</strong> ( 逻辑回归 ) ，尽管它的名字是回归，是一个用于分类的线性模型而不是用于回归。 </p>
<p>可以从 <strong>LogisticRegression</strong> 类中访问 <strong>scikit-learn</strong> 中 <strong>logistic regression</strong> ( 逻辑回归 ) 的实现。该实现可以拟合 <strong>binary</strong> ( 二进制 ) ，<strong>One-vs- Rest</strong> ( 一对一休息 ) 或 <strong>multinomial logistic regression</strong> ( 多项逻辑回归 ) 与可选的 <strong>L2</strong> 或 <strong>L1</strong> <strong>regularization</strong> ( 正则化 ) 。</p>
<p>作为优化问题，<strong>binary class L2 penalized logistic regression</strong> ( 二进制类 <strong>L2</strong> 惩罚逻辑回归 ) 使以下 <strong>cost function</strong> ( 成本函数 ) 最小化：</p>
<p><img src="http://scikit-learn.org/stable/_images/math/760c999ccbc78b72d2a91186ba55ce37f0d2cf37.png" alt="img"></p>
<p>类似地， <strong>L1 regularized logistic regression</strong> ( <strong>L1</strong> 正则化逻辑回归 ) 解决了以下优化问题:</p>
<p><img src="http://scikit-learn.org/stable/_images/math/6a0bcf21baaeb0c2b879ab74fe333c0aab0d6ae6.png" alt="img"></p>
<p>在 <strong>Logistic</strong> 回归类中实现的 <strong>solver</strong> ( 求解器 ) 是 <strong>“liblinear”</strong>, <strong>“newton-cg”</strong>, <strong>“lbfgs”</strong> and <strong>“sag”</strong>：</p>
<table>
<thead>
<tr>
<th>Case</th>
<th>“sag”</th>
</tr>
</thead>
<tbody>
<tr>
<td>Small dataset or L1 penalty</td>
<td>“liblinear”</td>
</tr>
<tr>
<td>Multinomial loss or large dataset</td>
<td>“lbfgs”, “sag” or “newton-cg”</td>
</tr>
<tr>
<td>Very Large dataset</td>
<td>“sag”</td>
</tr>
</tbody>
</table>
<h3 id="11、Robustness-regression-outliers-and-modeling-errors-鲁棒性回归：异常值和建模误差"><a href="#11、Robustness-regression-outliers-and-modeling-errors-鲁棒性回归：异常值和建模误差" class="headerlink" title="11、Robustness regression: outliers and modeling errors ( 鲁棒性回归：异常值和建模误差 )"></a>11、Robustness regression: outliers and modeling errors ( 鲁棒性回归：异常值和建模误差 )</h3><p>存在 <strong>presence of corrupt data</strong> ( 腐败数据 ) 的情况下拟合回归模型 </p>
<p>一般来说，在高维度设置（大 <strong>n_features</strong> ）中的 <strong>robust fitting</strong> ( 鲁棒拟合 ) 是非常困难的。这里的  <strong>robust models</strong> ( 健壮模型 ) 可能无法在这些设置中使用。 </p>
<p>Scikit-learn 提供了 3 个 robust regression estimators ( 鲁棒的回归估计 ) ：RANSAC ， Theil Sen 和 HuberRegressor</p>
<ul>
<li><a href="http://scikit-learn.org/stable/modules/linear_model.html#huber-regression" target="_blank" rel="noopener"><strong>HuberRegressor</strong> </a>应该比 <a href="http://scikit-learn.org/stable/modules/linear_model.html#ransac-regression" target="_blank" rel="noopener"><strong>RANSAC</strong> </a>和 <strong>Theil Sen</strong> 更快，除非样本数量非常大，即 <strong>n_samples &gt;&gt; n_features</strong> 。这是因为 <a href="http://scikit-learn.org/stable/modules/linear_model.html#ransac-regression" target="_blank" rel="noopener"><strong>RANSAC</strong> </a>和 <strong>Theil Sen</strong> 适合较小的数据子集。然而， <strong>Theil Sen</strong> 和 <strong>RANSAC</strong> 都不太可能像 <strong>HuberRegressor</strong> 一样强大的默认参数。</li>
<li><a href="http://scikit-learn.org/stable/modules/linear_model.html#ransac-regression" target="_blank" rel="noopener"><strong>RANSAC</strong> </a>比 <strong>Theil Sen</strong> 快，随着样品数量的增加而增加</li>
<li><a href="http://scikit-learn.org/stable/modules/linear_model.html#ransac-regression" target="_blank" rel="noopener"><strong>RANSAC</strong> </a>将在y方向处理较大的异常值（最常见的情况）</li>
<li><strong>Theil Sen</strong> 将在 X 方向处理中等大小的异常值，但是这个属性将在高维度设置中消失。</li>
<li>如有疑问，请使用 RANSAC </li>
</ul>
<h3 id="12、Polynomial-regression-extending-linear-models-with-basis-functions-多项式回归：用基函数扩展线性模型"><a href="#12、Polynomial-regression-extending-linear-models-with-basis-functions-多项式回归：用基函数扩展线性模型" class="headerlink" title="12、Polynomial regression: extending linear models with basis functions ( 多项式回归：用基函数扩展线性模型 )"></a>12、Polynomial regression: extending linear models with basis functions ( 多项式回归：用基函数扩展线性模型 )</h3><p>我们看到所得到的多项式回归与上面我们考虑过的线性模型相同（即模型在 <strong>w</strong> 中是线性的），并且可以通过相同的技术来解决。通过考虑使用这些基本功能构建的更高维度空间内的线性拟合，该模型具有适应更广泛范围的数据的灵活性。 </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/22/机器学习/各种优化算法的比较/" rel="next" title="各种优化算法的比较">
                <i class="fa fa-chevron-left"></i> 各种优化算法的比较
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/24/机器学习/朴素贝叶斯/" rel="prev" title="朴素贝叶斯">
                朴素贝叶斯 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://i.loli.net/2018/07/21/5b5347273dca4.jpg"
                alt="" />
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description">Winter is coming!</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jie786389209" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="http://blog.csdn.net/weixin_41123612" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-crosshairs"></i>CSDN</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#广义线性模型"><span class="nav-number">1.</span> <span class="nav-text">广义线性模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1、普通最小二乘法"><span class="nav-number">2.</span> <span class="nav-text">1、普通最小二乘法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#"><span class="nav-number">3.</span> <span class="nav-text"> </span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2、岭回归、岭回归加交叉验证"><span class="nav-number">4.</span> <span class="nav-text">2、岭回归、岭回归加交叉验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3、Lasso"><span class="nav-number">5.</span> <span class="nav-text">3、Lasso</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6、LARS-Lasso使用最小角度回归的拉索算法"><span class="nav-number">6.</span> <span class="nav-text">6、LARS Lasso使用最小角度回归的拉索算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7、Orthogonal-Matching-Pursuit-OMP-正交匹配追踪（OMP）"><span class="nav-number">7.</span> <span class="nav-text">7、Orthogonal Matching Pursuit (OMP) ( 正交匹配追踪（OMP） )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8、Bayesian-Regression-贝叶斯回归"><span class="nav-number">8.</span> <span class="nav-text">8、Bayesian Regression ( 贝叶斯回归 )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9、Automatic-Relevance-Determination-ARD-自动相关性测定-ARD"><span class="nav-number">9.</span> <span class="nav-text">9、Automatic Relevance Determination - ARD ( 自动相关性测定 - ARD )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10、Logistic-regression-逻辑回归"><span class="nav-number">10.</span> <span class="nav-text">10、Logistic regression ( 逻辑回归 )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11、Robustness-regression-outliers-and-modeling-errors-鲁棒性回归：异常值和建模误差"><span class="nav-number">11.</span> <span class="nav-text">11、Robustness regression: outliers and modeling errors ( 鲁棒性回归：异常值和建模误差 )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12、Polynomial-regression-extending-linear-models-with-basis-functions-多项式回归：用基函数扩展线性模型"><span class="nav-number">12.</span> <span class="nav-text">12、Polynomial regression: extending linear models with basis functions ( 多项式回归：用基函数扩展线性模型 )</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
